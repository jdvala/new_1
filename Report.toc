\contentsline {chapter}{\numberline {1}Introduction}{1}
\contentsline {section}{\numberline {1.1}Intrusion Detection System}{1}
\contentsline {section}{\numberline {1.2}Classification of Intrusion Detection System}{2}
\contentsline {subsection}{\numberline {1.2.1}Network Intrusion Detection System}{2}
\contentsline {subsection}{\numberline {1.2.2}Host based Intrusion Detection System}{2}
\contentsline {section}{\numberline {1.3}Advantages of Network Based Intrusion Detection System}{2}
\contentsline {section}{\numberline {1.4}Advantages of Host Based Intrusion Detection System}{3}
\contentsline {section}{\numberline {1.5}Limitations of Intrusion Detection Systems}{3}
\contentsline {chapter}{\numberline {2}Tensorflow}{4}
\contentsline {section}{\numberline {2.1}Introduction}{4}
\contentsline {section}{\numberline {2.2}Graph Construction and Basic Programming Concept}{5}
\contentsline {subsection}{\numberline {2.2.1}Operations, Kernels, Variables, and Sessions}{5}
\contentsline {subsubsection}{Operations and Kernels}{5}
\contentsline {subsubsection}{Variables}{5}
\contentsline {subsubsection}{Session}{5}
\contentsline {subsection}{\numberline {2.2.2}Tensor}{5}
\contentsline {chapter}{\numberline {3}Deep Neural Networks}{6}
\contentsline {section}{\numberline {3.1}Introduction}{6}
\contentsline {section}{\numberline {3.2}Artificial Neural Network}{6}
\contentsline {section}{\numberline {3.3}Artificial Neural Networks: Types}{8}
\contentsline {section}{\numberline {3.4}Training a Deep Neural Network}{9}
\contentsline {subsection}{\numberline {3.4.1}Supervised Learning}{9}
\contentsline {subsection}{\numberline {3.4.2}Unsupervised Learning}{10}
\contentsline {subsection}{\numberline {3.4.3}Reinforcement Learning}{11}
\contentsline {subsection}{\numberline {3.4.4}Activation Functions}{12}
\contentsline {subsubsection}{Sigmoid Activation Function}{12}
\contentsline {subsubsection}{Step Function}{13}
\contentsline {subsubsection}{Rectified Linear Unit (ReLU)}{13}
\contentsline {subsubsection}{TanH Activation Function}{14}
\contentsline {subsubsection}{Exponential Linear Unit (eLU)}{14}
\contentsline {subsubsection}{Softmax Activation Function}{14}
\contentsline {subsubsection}{Softplus Activation Function}{15}
\contentsline {subsection}{\numberline {3.4.5}Optimization Algorithm}{15}
\contentsline {subsubsection}{Stochastic Gradient Descent Optimizer}{15}
\contentsline {subsubsection}{Adam Optimizer}{16}
\contentsline {subsubsection}{Momentum Optimizer}{16}
\contentsline {subsubsection}{RMSProp Optimizer}{16}
\contentsline {section}{\numberline {3.5}Challenges in Training a Deep Neural Network}{16}
\contentsline {section}{\numberline {3.6}Stacked Autoencoder}{17}
\contentsline {subsection}{\numberline {3.6.1}Structure}{17}
\contentsline {subsection}{\numberline {3.6.2}Types of Autoencoders}{18}
\contentsline {subsubsection}{Denoising Autoencoders}{18}
\contentsline {subsubsection}{Sparse Autoencoder}{18}
\contentsline {section}{\numberline {3.7}Deep Belief Networks}{19}
\contentsline {subsection}{\numberline {3.7.1}Restricted Boltzmann Machine}{19}
\contentsline {subsection}{\numberline {3.7.2}Greedy Layer-Wise Training of Neural Networks}{19}
\contentsline {chapter}{\numberline {4}Evaluation and Results}{21}
\contentsline {section}{\numberline {4.1}The Approach}{21}
\contentsline {subsection}{\numberline {4.1.1}Parameters}{21}
\contentsline {subsubsection}{Learning Rate}{21}
\contentsline {subsubsection}{Epochs}{21}
\contentsline {subsubsection}{Batch Size}{21}
\contentsline {subsubsection}{Accuracy}{22}
\contentsline {subsubsection}{Precision (P)}{22}
\contentsline {subsubsection}{Recall (R)}{22}
\contentsline {subsubsection}{F-Measure (F1-Score)}{22}
\contentsline {section}{\numberline {4.2}Data Set Evaluation}{23}
\contentsline {section}{\numberline {4.3}Stacked Autoencoder}{23}
\contentsline {subsection}{\numberline {4.3.1}Results}{23}
\contentsline {subsection}{\numberline {4.3.2}Adam Optimizer}{24}
\contentsline {subsubsection}{Sigmoid Activation}{25}
\contentsline {subsubsection}{ReLU Activation}{25}
\contentsline {subsubsection}{eLU Activation}{26}
\contentsline {subsubsection}{Softplus Activation}{26}
\contentsline {subsection}{\numberline {4.3.3}RMSProp Optimizer}{27}
\contentsline {subsubsection}{Sigmoid Activation}{28}
\contentsline {subsubsection}{ReLU Activation}{28}
\contentsline {subsubsection}{eLU Activation}{28}
\contentsline {subsubsection}{Softplus Activation}{29}
\contentsline {subsection}{\numberline {4.3.4}Stochastic Gradient Descent Optimizer}{29}
\contentsline {subsubsection}{Sigmoid Activation}{30}
\contentsline {subsubsection}{ReLU Activation}{30}
\contentsline {subsubsection}{eLU Activation}{31}
\contentsline {subsubsection}{Softplus Activation}{31}
\contentsline {subsection}{\numberline {4.3.5}Momentum Optimizer}{32}
\contentsline {subsubsection}{Sigmoid Activation}{33}
\contentsline {subsubsection}{ReLU Activation}{33}
\contentsline {subsubsection}{eLU Activation}{33}
\contentsline {subsubsection}{Softplus Activation}{34}
\contentsline {section}{\numberline {4.4}Deep Belief Network}{35}
\contentsline {subsubsection}{Adam Optimizer}{36}
\contentsline {subsubsection}{Momentum Optimizer}{36}
\contentsline {subsubsection}{RMSProp}{37}
\contentsline {subsubsection}{Stochastic Gradient Descent Optimizer}{37}
\contentsline {chapter}{\numberline {5}Conclusion}{38}
\contentsline {chapter}{Appendix \numberline {A}Results of Supervised Training of Stacked Autoencoder}{41}
\contentsline {section}{\numberline {A.1}Adam Optimizer}{42}
\contentsline {subsection}{\numberline {A.1.1}Sigmoid Activation}{43}
\contentsline {subsection}{\numberline {A.1.2}ReLu Activation}{43}
\contentsline {subsection}{\numberline {A.1.3}eLu Activation}{43}
\contentsline {subsection}{\numberline {A.1.4}Softplus Activation}{44}
\contentsline {section}{\numberline {A.2}RMSProp Optimizer}{44}
\contentsline {subsection}{\numberline {A.2.1}Sigmoid Activation}{45}
\contentsline {subsection}{\numberline {A.2.2}ReLu Activation}{45}
\contentsline {subsection}{\numberline {A.2.3}eLu Activation}{46}
\contentsline {subsection}{\numberline {A.2.4}Softplus Activation}{46}
\contentsline {section}{\numberline {A.3}Stochastic Gradient Descent Optimizer}{47}
\contentsline {subsection}{\numberline {A.3.1}Sigmoid Activation}{48}
\contentsline {subsection}{\numberline {A.3.2}ReLU Activation}{48}
\contentsline {subsection}{\numberline {A.3.3}eLu Activation}{48}
\contentsline {subsection}{\numberline {A.3.4}Softplus Activation}{49}
\contentsline {section}{\numberline {A.4}Momentum Optimizer}{49}
\contentsline {subsection}{\numberline {A.4.1}Sigmoid Activation}{50}
\contentsline {subsection}{\numberline {A.4.2}ReLU Activation}{50}
\contentsline {subsection}{\numberline {A.4.3}eLu Activation}{51}
\contentsline {subsection}{\numberline {A.4.4}Softplus Activation}{51}
\contentsline {chapter}{Appendix \numberline {B}Unsupervised Training Results of Stacked Autoencoder}{52}
\contentsline {section}{\numberline {B.1}Adam Optimizer}{52}
\contentsline {subsection}{\numberline {B.1.1}Sigmoid Activation}{53}
\contentsline {subsection}{\numberline {B.1.2}ReLU Activation}{53}
\contentsline {subsection}{\numberline {B.1.3}eLU Activation}{54}
\contentsline {subsection}{\numberline {B.1.4}Softplus Activation}{54}
\contentsline {section}{\numberline {B.2}RMSProp Optimizer}{55}
\contentsline {subsection}{\numberline {B.2.1}Sigmoid Activation}{56}
\contentsline {subsection}{\numberline {B.2.2}ReLU Activation}{56}
\contentsline {subsection}{\numberline {B.2.3}eLU Activation}{56}
\contentsline {subsection}{\numberline {B.2.4}Softplus Activation}{57}
\contentsline {section}{\numberline {B.3}Stochastic Gradient Descent Optimizer}{58}
\contentsline {subsection}{\numberline {B.3.1}Sigmoid Activation}{59}
\contentsline {subsection}{\numberline {B.3.2}ReLU Activation}{59}
\contentsline {subsection}{\numberline {B.3.3}eLU Activation}{59}
\contentsline {subsection}{\numberline {B.3.4}Softplus Activation}{60}
\contentsline {section}{\numberline {B.4}Momentum Optimizer}{60}
\contentsline {subsection}{\numberline {B.4.1}Sigmoid Activation}{61}
\contentsline {subsection}{\numberline {B.4.2}ReLU Activation}{61}
\contentsline {subsection}{\numberline {B.4.3}eLU Activation}{62}
\contentsline {subsection}{\numberline {B.4.4}Softplus Activation}{62}
