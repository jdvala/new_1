\contentsline {chapter}{\numberline {1}Introduction}{1}
\contentsline {section}{\numberline {1.1}Intrusion Detection System}{1}
\contentsline {section}{\numberline {1.2}Classification of Intrusion Detection System}{2}
\contentsline {subsection}{\numberline {1.2.1}Network Intrusion Detection System}{2}
\contentsline {subsection}{\numberline {1.2.2}Host based Intrusion Detection System}{2}
\contentsline {section}{\numberline {1.3}Advantages of Network Based Intrusion Detection System}{2}
\contentsline {section}{\numberline {1.4}Advantages of Host Based Intrusion Detection System}{3}
\contentsline {section}{\numberline {1.5}Limitations of Intrusion Detection Systems}{3}
\contentsline {chapter}{\numberline {2}Tensorflow}{4}
\contentsline {section}{\numberline {2.1}Introduction}{4}
\contentsline {section}{\numberline {2.2}Graph Construction and Basic Programming Concept}{5}
\contentsline {subsection}{\numberline {2.2.1}Operations, Kernels, Variables, and Sessions}{5}
\contentsline {subsubsection}{Operations and Kernels}{5}
\contentsline {subsubsection}{Variables}{5}
\contentsline {subsubsection}{Session}{5}
\contentsline {subsection}{\numberline {2.2.2}Tensor}{5}
\contentsline {chapter}{\numberline {3}Deep Neural Network}{6}
\contentsline {section}{\numberline {3.1}Introduction}{6}
\contentsline {section}{\numberline {3.2}Artificial Neural Network}{6}
\contentsline {section}{\numberline {3.3}Artificial Neural Networks: Types}{8}
\contentsline {section}{\numberline {3.4}Training A Deep Neural Network}{9}
\contentsline {subsection}{\numberline {3.4.1}Supervised Learning}{9}
\contentsline {subsection}{\numberline {3.4.2}Unsupervised Learning}{10}
\contentsline {subsection}{\numberline {3.4.3}Reinforcement Learning}{11}
\contentsline {subsection}{\numberline {3.4.4}Activation Functions}{12}
\contentsline {subsubsection}{Sigmoid Activation Function}{12}
\contentsline {subsubsection}{Step Function}{13}
\contentsline {subsubsection}{Rectified Linear Unit}{13}
\contentsline {subsubsection}{TanH Activation Function}{14}
\contentsline {subsubsection}{Exponential Linear Unit}{14}
\contentsline {subsubsection}{Softmax Activation Function}{14}
\contentsline {subsection}{\numberline {3.4.5}Optimization Algorithm}{15}
\contentsline {subsubsection}{Stochastic Gradient Descent Optimizer}{15}
\contentsline {subsubsection}{Adam Optimizer}{15}
\contentsline {subsubsection}{Momentum Optimizer}{15}
\contentsline {subsubsection}{RMSProp Optimizer}{16}
\contentsline {section}{\numberline {3.5}Challenges in Training A Deep Neural Network}{16}
\contentsline {section}{\numberline {3.6}Stacked Autoencoder}{16}
\contentsline {subsection}{\numberline {3.6.1}Structure}{16}
\contentsline {subsection}{\numberline {3.6.2}Types of Autoencoders}{18}
\contentsline {subsubsection}{Denoising Autoencoders}{18}
\contentsline {subsubsection}{Sparse Autoencoder}{18}
\contentsline {section}{\numberline {3.7}Deep Belief Networks}{19}
\contentsline {subsection}{\numberline {3.7.1}Restricted Boltzmann Machine}{19}
\contentsline {subsection}{\numberline {3.7.2}Greedy Layer-Wise Training of Neural Networks}{19}
\contentsline {chapter}{\numberline {4}Evaluation and Results}{20}
\contentsline {section}{\numberline {4.1}The Approach}{20}
\contentsline {subsection}{\numberline {4.1.1}Parameters}{20}
\contentsline {subsubsection}{Learning Rate}{20}
\contentsline {subsubsection}{Epochs}{20}
\contentsline {subsubsection}{Batch Size}{20}
\contentsline {subsubsection}{Accuracy}{21}
\contentsline {subsubsection}{Precision (P)}{21}
\contentsline {subsubsection}{Recall (R)}{21}
\contentsline {subsubsection}{F-Measure (F1-Score)}{21}
\contentsline {section}{\numberline {4.2}Data Set Evaluation}{22}
\contentsline {section}{\numberline {4.3}Stacked Autoencoder}{22}
\contentsline {subsection}{\numberline {4.3.1}Results}{22}
\contentsline {subsection}{\numberline {4.3.2}Adam Optimizer}{23}
\contentsline {subsubsection}{Sigmoid Activation}{24}
\contentsline {subsubsection}{ReLU Activation}{24}
\contentsline {subsubsection}{eLU Activation}{25}
\contentsline {subsubsection}{Softplus Activation}{25}
\contentsline {subsection}{\numberline {4.3.3}RMSProp Optimizer}{26}
\contentsline {subsubsection}{Sigmoid Activation}{27}
\contentsline {subsubsection}{ReLU Activation}{27}
\contentsline {subsubsection}{eLU Activation}{27}
\contentsline {subsubsection}{Softplus Activation}{28}
\contentsline {subsection}{\numberline {4.3.4}Stochastic Gradient Descent Optimizer}{28}
\contentsline {subsubsection}{Sigmoid Activation}{29}
\contentsline {subsubsection}{ReLU Activation}{29}
\contentsline {subsubsection}{eLU Activation}{30}
\contentsline {subsubsection}{Softplus Activation}{30}
\contentsline {subsection}{\numberline {4.3.5}Momentum Optimizer}{31}
\contentsline {subsubsection}{Sigmoid Activation}{32}
\contentsline {subsubsection}{ReLU Activation}{32}
\contentsline {subsubsection}{eLU Activation}{32}
\contentsline {subsubsection}{Softplus Activation}{33}
\contentsline {section}{\numberline {4.4}Deep Belief Network}{34}
\contentsline {subsubsection}{Adam Optimizer}{35}
\contentsline {subsubsection}{Momentum Optimizer}{35}
\contentsline {subsubsection}{RMSProp}{36}
\contentsline {subsubsection}{Stochastic Gradient Descent Optimizer}{36}
\contentsline {chapter}{Appendix \numberline {A}Results of Supervised Training of Stacked Autoencoder}{39}
\contentsline {section}{\numberline {A.1}Adam Optimizer}{40}
\contentsline {subsection}{\numberline {A.1.1}Sigmoid Activation}{41}
\contentsline {subsection}{\numberline {A.1.2}ReLu Activation}{41}
\contentsline {subsection}{\numberline {A.1.3}eLu Activation}{41}
\contentsline {subsection}{\numberline {A.1.4}Softplus Activation}{42}
\contentsline {section}{\numberline {A.2}RMSProp Optimizer}{42}
\contentsline {subsection}{\numberline {A.2.1}Sigmoid Activation}{43}
\contentsline {subsection}{\numberline {A.2.2}ReLu Activation}{43}
\contentsline {subsection}{\numberline {A.2.3}eLu Activation}{44}
\contentsline {subsection}{\numberline {A.2.4}Softplus Activation}{44}
\contentsline {section}{\numberline {A.3}Stochastic Gradient Descent Optimizer}{45}
\contentsline {subsection}{\numberline {A.3.1}Sigmoid Activation}{46}
\contentsline {subsection}{\numberline {A.3.2}ReLU Activation}{46}
\contentsline {subsection}{\numberline {A.3.3}eLu Activation}{46}
\contentsline {subsection}{\numberline {A.3.4}Softplus Activation}{47}
\contentsline {section}{\numberline {A.4}Momentum Optimizer}{47}
\contentsline {subsection}{\numberline {A.4.1}Sigmoid Activation}{48}
\contentsline {subsection}{\numberline {A.4.2}ReLU Activation}{48}
\contentsline {subsection}{\numberline {A.4.3}eLu Activation}{49}
\contentsline {subsection}{\numberline {A.4.4}Softplus Activation}{49}
\contentsline {chapter}{Appendix \numberline {B}Unsupervised Training Results of Stacked Autoencoder}{50}
\contentsline {section}{\numberline {B.1}Adam Optimizer}{50}
\contentsline {subsection}{\numberline {B.1.1}Sigmoid Activation}{51}
\contentsline {subsection}{\numberline {B.1.2}ReLU Activation}{51}
\contentsline {subsection}{\numberline {B.1.3}eLU Activation}{52}
\contentsline {subsection}{\numberline {B.1.4}Softplus Activation}{52}
\contentsline {section}{\numberline {B.2}RMSProp Optimizer}{53}
\contentsline {subsection}{\numberline {B.2.1}Sigmoid Activation}{54}
\contentsline {subsection}{\numberline {B.2.2}ReLU Activation}{54}
\contentsline {subsection}{\numberline {B.2.3}eLU Activation}{54}
\contentsline {subsection}{\numberline {B.2.4}Softplus Activation}{55}
\contentsline {section}{\numberline {B.3}Stochastic Gradient Descent Optimizer}{56}
\contentsline {subsection}{\numberline {B.3.1}Sigmoid Activation}{57}
\contentsline {subsection}{\numberline {B.3.2}ReLU Activation}{57}
\contentsline {subsection}{\numberline {B.3.3}eLU Activation}{57}
\contentsline {subsection}{\numberline {B.3.4}Softplus Activation}{58}
\contentsline {section}{\numberline {B.4}Momentum Optimizer}{58}
\contentsline {subsection}{\numberline {B.4.1}Sigmoid Activation}{59}
\contentsline {subsection}{\numberline {B.4.2}ReLU Activation}{59}
\contentsline {subsection}{\numberline {B.4.3}eLU Activation}{60}
\contentsline {subsection}{\numberline {B.4.4}Softplus Activation}{60}
