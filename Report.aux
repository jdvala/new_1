\relax 
\citation{Kaspersky}
\citation{IDS}
\citation{IDS}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:intro}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Intrusion Detection System}{1}}
\newlabel{sec:introintrusion}{{1.1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Classification of Intrusion Detection System}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Network Intrusion Detection System}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Host based Intrusion Detection System}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Advantages of Network Based Intrusion Detection System}{2}}
\newlabel{sec:advantagesofNIDS}{{1.3}{2}}
\citation{securityengineering}
\citation{securityengineering}
\citation{limitationOfIDS}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Advantages of Host Based Intrusion Detection System}{3}}
\newlabel{sec:advantagesHostBasedIDS}{{1.4}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Limitations of Intrusion Detection Systems}{3}}
\newlabel{sec:limitsofIDS}{{1.5}{3}}
\citation{tensorflow_paper}
\citation{googleSearch}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Tensorflow}{4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:tensorflow}{{2}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction}{4}}
\newlabel{sec:tensor_intro}{{2.1}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Graph Construction and Basic Programming Concept}{5}}
\newlabel{sec:programmingtensorflow}{{2.2}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Operations, Kernels, Variables, and Sessions}{5}}
\newlabel{sec:constituentsoftensorflow}{{2.2.1}{5}}
\@writefile{toc}{\contentsline {subsubsection}{Operations and Kernels}{5}}
\newlabel{sec:ops_kernel}{{2.2.1}{5}}
\@writefile{toc}{\contentsline {subsubsection}{Variables}{5}}
\newlabel{variables}{{2.2.1}{5}}
\@writefile{toc}{\contentsline {subsubsection}{Session}{5}}
\newlabel{session}{{2.2.1}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Tensor}{5}}
\newlabel{tensor}{{2.2.2}{5}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Deep Neural Network}{6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:DNN}{{3}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introduction}{6}}
\newlabel{sec:intro_dnn}{{3.1}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Artificial Neural Network}{6}}
\newlabel{ANN}{{3.2}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Structure of Artificial Neuron\relax }}{7}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:AN}{{1}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Structure of Artificial Neural Network\relax }}{8}}
\newlabel{fig:NN}{{2}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Artificial Neural Networks: Types}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Feed Forward and Recurrent Neural Network\relax }}{8}}
\newlabel{fig:FFRN}{{3}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Training A Deep Neural Network}{9}}
\newlabel{train}{{3.4}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Supervised Learning}{9}}
\newlabel{sec:supervisedLearning}{{3.4.1}{9}}
\citation{unsupervised}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Supervised Learning\relax }}{10}}
\newlabel{fig:supervised}{{4}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Unsupervised Learning}{10}}
\newlabel{sec:unsupervised}{{3.4.2}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Unsupervised Learning\relax }}{11}}
\newlabel{fig:cluster}{{5}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Reinforcement Learning}{11}}
\newlabel{sec:ReinforcementLearning}{{3.4.3}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Reinforcement Learning\relax }}{11}}
\newlabel{fig:reinforcement}{{6}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Activation Functions}{12}}
\newlabel{activationfunction}{{3.4.4}{12}}
\@writefile{toc}{\contentsline {subsubsection}{Sigmoid Activation Function}{12}}
\newlabel{sec:sigmoid}{{3.4.4}{12}}
\newlabel{eq:sig}{{1}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Sigmoid Activation Function\relax }}{12}}
\newlabel{fig:sigmoid}{{7}{12}}
\citation{ReLU}
\@writefile{toc}{\contentsline {subsubsection}{Step Function}{13}}
\newlabel{sec:step}{{3.4.4}{13}}
\newlabel{eq:step}{{2}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Step Activation Function\relax }}{13}}
\newlabel{fig:step}{{8}{13}}
\@writefile{toc}{\contentsline {subsubsection}{Rectified Linear Unit}{13}}
\newlabel{sec:ReLU}{{3.4.4}{13}}
\newlabel{eq:ReLU}{{3}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Rectified Linear Unit Activation Function\relax }}{13}}
\newlabel{fig:ReLU}{{9}{13}}
\citation{ELU}
\@writefile{toc}{\contentsline {subsubsection}{TanH Activation Function}{14}}
\newlabel{sec:tanh}{{3.4.4}{14}}
\newlabel{eq:tanh}{{4}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces TanH Activation Function\relax }}{14}}
\newlabel{fig:tanh}{{10}{14}}
\@writefile{toc}{\contentsline {subsubsection}{Exponential Linear Unit}{14}}
\newlabel{sec:ELU}{{3.4.4}{14}}
\newlabel{eq:ELU}{{5}{14}}
\@writefile{toc}{\contentsline {subsubsection}{Softmax Activation Function}{14}}
\newlabel{sec:softmax}{{3.4.4}{14}}
\newlabel{eq:softmax}{{6}{14}}
\citation{OptimizerGeneral}
\citation{OptimizerGeneral}
\citation{momentum}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.5}Optimization Algorithm}{15}}
\newlabel{optimizer}{{3.4.5}{15}}
\@writefile{toc}{\contentsline {subsubsection}{Stochastic Gradient Descent Optimizer}{15}}
\newlabel{sgd}{{3.4.5}{15}}
\@writefile{toc}{\contentsline {subsubsection}{Adam Optimizer}{15}}
\newlabel{adam}{{3.4.5}{15}}
\@writefile{toc}{\contentsline {subsubsection}{Momentum Optimizer}{15}}
\newlabel{momentum}{{3.4.5}{15}}
\citation{OptimizerGeneral}
\citation{challenge1}
\citation{challenge2}
\citation{autoencoder}
\citation{autoencoder2}
\@writefile{toc}{\contentsline {subsubsection}{RMSProp Optimizer}{16}}
\newlabel{RMSProp}{{3.4.5}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Challenges in Training A Deep Neural Network}{16}}
\newlabel{challenges}{{3.5}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Stacked Autoencoder}{16}}
\newlabel{Autoencoder}{{3.6}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Structure}{16}}
\newlabel{structure}{{3.6.1}{16}}
\newlabel{eq:autoencoder_eq}{{7}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Autoencoder with single hidden layer\relax }}{17}}
\newlabel{fig:autoencoder}{{11}{17}}
\citation{ksparseautoencoder}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}Types of Autoencoders}{18}}
\newlabel{sec:types_autoencoder}{{3.6.2}{18}}
\@writefile{toc}{\contentsline {subsubsection}{Denoising Autoencoders}{18}}
\newlabel{sec:denoising_autoencoder}{{3.6.2}{18}}
\@writefile{toc}{\contentsline {subsubsection}{Sparse Autoencoder}{18}}
\newlabel{sec:sparse_autoencoder}{{3.6.2}{18}}
\citation{DBN}
\citation{RBM}
\citation{RBMuses}
\citation{Greedy}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Deep Belief Networks}{19}}
\newlabel{sec:deep_belief_network}{{3.7}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.1}Restricted Boltzmann Machine}{19}}
\newlabel{sec:RBM}{{3.7.1}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Deep Belief Network\relax }}{19}}
\newlabel{fig:RBM}{{12}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.2}Greedy Layer-Wise Training of Neural Networks}{19}}
\newlabel{greedy}{{3.7.2}{19}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Evaluation and Results}{20}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:EvaluationAndResults}{{4}{20}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}The Approach}{20}}
\newlabel{approach}{{4.1}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Parameters}{20}}
\@writefile{toc}{\contentsline {subsubsection}{Learning Rate}{20}}
\@writefile{toc}{\contentsline {subsubsection}{Epochs}{20}}
\@writefile{toc}{\contentsline {subsubsection}{Batch Size}{20}}
\@writefile{toc}{\contentsline {subsubsection}{Accuracy}{21}}
\@writefile{toc}{\contentsline {subsubsection}{Precision (P)}{21}}
\@writefile{toc}{\contentsline {subsubsection}{Recall (R)}{21}}
\@writefile{toc}{\contentsline {subsubsection}{F-Measure (F1-Score)}{21}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Data Set Evaluation}{22}}
\newlabel{sec:datasetEvaluation}{{4.2}{22}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Distribution of records in Test and Train Set\relax }}{22}}
\newlabel{table:test_train}{{4.1}{22}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Stacked Autoencoder}{22}}
\newlabel{sec:autoencoder}{{4.3}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Results}{22}}
\newlabel{results}{{4.3.1}{22}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Configuration of Autoencoder for Greedy Layer-Wise Pre-Training\relax }}{23}}
\newlabel{config_auto_greedy}{{4.2}{23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Adam Optimizer}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces  Accuracy of Adam Optimizer for different activation functions\relax }}{23}}
\newlabel{fig:accuracy_adam_greedy}{{13}{23}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Number of samples correctly identified for Adam Optimizer with different Activation functions\relax }}{24}}
\newlabel{confusion_adam}{{4.3}{24}}
\@writefile{toc}{\contentsline {subsubsection}{Sigmoid Activation}{24}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Adam Optimizer for Sigmoid Activation\relax }}{24}}
\newlabel{prf1_adam_sigmoid_auto}{{4.4}{24}}
\@writefile{toc}{\contentsline {subsubsection}{ReLU Activation}{24}}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Adam Optimizer for ReLU Activation\relax }}{24}}
\newlabel{prf1_adam_relu_auto}{{4.5}{24}}
\@writefile{toc}{\contentsline {subsubsection}{eLU Activation}{25}}
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Adam Optimizer for eLU Activation\relax }}{25}}
\newlabel{prf1_adam_elu_auto}{{4.6}{25}}
\@writefile{toc}{\contentsline {subsubsection}{Softplus Activation}{25}}
\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Adam Optimizer for Softplus Activation\relax }}{25}}
\newlabel{prf1_adam_softplus_auto}{{4.7}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}RMSProp Optimizer}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces  Accuracy of RMSProp Optimizer for different activation functions\relax }}{26}}
\newlabel{fig:accuracy_rmsprop_greedy}{{14}{26}}
\@writefile{lot}{\contentsline {table}{\numberline {4.8}{\ignorespaces Number of samples correctly identified for RMSProp Optimizer with different Activation functions\relax }}{26}}
\newlabel{confusion_rmsprop}{{4.8}{26}}
\@writefile{toc}{\contentsline {subsubsection}{Sigmoid Activation}{27}}
\@writefile{lot}{\contentsline {table}{\numberline {4.9}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with RMSProp Optimizer for Sigmoid Activation\relax }}{27}}
\newlabel{prf1_rmsprop_sigmoid_auto}{{4.9}{27}}
\@writefile{toc}{\contentsline {subsubsection}{ReLU Activation}{27}}
\@writefile{lot}{\contentsline {table}{\numberline {4.10}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with RMSProp Optimizer for ReLU Activation\relax }}{27}}
\newlabel{prf1_rmsprop_relu_auto}{{4.10}{27}}
\@writefile{toc}{\contentsline {subsubsection}{eLU Activation}{27}}
\@writefile{lot}{\contentsline {table}{\numberline {4.11}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with RMSProp Optimizer for eLU Activation\relax }}{27}}
\newlabel{prf1_rmsprop_elu_auto}{{4.11}{27}}
\@writefile{toc}{\contentsline {subsubsection}{Softplus Activation}{28}}
\@writefile{lot}{\contentsline {table}{\numberline {4.12}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with RMSProp Optimizer for Softplus Activation\relax }}{28}}
\newlabel{prf1_rmsprop_elu_auto}{{4.12}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Stochastic Gradient Descent Optimizer}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces  Accuracy of Stochastic Gradient Descent Optimizer for different activation functions\relax }}{28}}
\newlabel{fig:accuracy_sgd_greedy}{{15}{28}}
\@writefile{lot}{\contentsline {table}{\numberline {4.13}{\ignorespaces Number of samples correctly identified for Stochastic Gradient Descent Optimizer with different Activation functions\relax }}{29}}
\newlabel{confusion_sgd_greedy}{{4.13}{29}}
\@writefile{toc}{\contentsline {subsubsection}{Sigmoid Activation}{29}}
\@writefile{lot}{\contentsline {table}{\numberline {4.14}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Stochastic Gradient Descent Optimizer for Sigmoid Activation\relax }}{29}}
\newlabel{prf1_sgd_sigmoid_auto}{{4.14}{29}}
\@writefile{toc}{\contentsline {subsubsection}{ReLU Activation}{29}}
\@writefile{lot}{\contentsline {table}{\numberline {4.15}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Stochastic Gradient Descent Optimizer for ReLU Activation\relax }}{29}}
\newlabel{prf1_sgd_relu_auto}{{4.15}{29}}
\@writefile{toc}{\contentsline {subsubsection}{eLU Activation}{30}}
\@writefile{lot}{\contentsline {table}{\numberline {4.16}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Stochastic Gradient Descent Optimizer for eLU Activation\relax }}{30}}
\newlabel{prf1_sgd_elu_auto}{{4.16}{30}}
\@writefile{toc}{\contentsline {subsubsection}{Softplus Activation}{30}}
\@writefile{lot}{\contentsline {table}{\numberline {4.17}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Stochastic Gradient Descent Optimizer for Softplus Activation\relax }}{30}}
\newlabel{prf1_rmsprop_elu_auto}{{4.17}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.5}Momentum Optimizer}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces  Accuracy of Momentum Optimizer for different activation functions\relax }}{31}}
\newlabel{fig:accuracy_mom_greedy}{{16}{31}}
\@writefile{lot}{\contentsline {table}{\numberline {4.18}{\ignorespaces Number of samples correctly identified for Momentum Optimizer with different Activation functions\relax }}{31}}
\newlabel{confusion_mom}{{4.18}{31}}
\@writefile{toc}{\contentsline {subsubsection}{Sigmoid Activation}{32}}
\@writefile{lot}{\contentsline {table}{\numberline {4.19}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Momentum Optimizer for Sigmoid Activation\relax }}{32}}
\newlabel{prf1_mom_sigmoid_auto}{{4.19}{32}}
\@writefile{toc}{\contentsline {subsubsection}{ReLU Activation}{32}}
\@writefile{lot}{\contentsline {table}{\numberline {4.20}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Momentum Optimizer for ReLU Activation\relax }}{32}}
\newlabel{prf1_mom_relu_auto}{{4.20}{32}}
\@writefile{toc}{\contentsline {subsubsection}{eLU Activation}{32}}
\@writefile{lot}{\contentsline {table}{\numberline {4.21}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Momentum Optimizer for eLU Activation\relax }}{32}}
\newlabel{prf1_mom_elu_auto}{{4.21}{32}}
\@writefile{toc}{\contentsline {subsubsection}{Softplus Activation}{33}}
\@writefile{lot}{\contentsline {table}{\numberline {4.22}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Momentum Optimizer for Softplus Activation\relax }}{33}}
\newlabel{prf1_mom_elu_auto}{{4.22}{33}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Deep Belief Network}{34}}
\newlabel{sec:dbn_eval}{{4.4}{34}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces  Accuracy of Deep Belief Network with different optimizers for Sigmoid activation \relax }}{34}}
\newlabel{fig:dbn_accu_sigmoid}{{17}{34}}
\@writefile{lot}{\contentsline {table}{\numberline {4.23}{\ignorespaces Parameters of DBN with Sigmoid Activation\relax }}{34}}
\newlabel{DBNSigmoidMomentum}{{4.23}{34}}
\@writefile{lot}{\contentsline {table}{\numberline {4.24}{\ignorespaces Number of samples correctly identified for DBN for different Optimizers with Sigmoid Activation functions\relax }}{35}}
\newlabel{DBN_predicted_attacks}{{4.24}{35}}
\@writefile{toc}{\contentsline {subsubsection}{Adam Optimizer}{35}}
\@writefile{lot}{\contentsline {table}{\numberline {4.25}{\ignorespaces Precision, Recall, and F1 Score of DBN with Adam Optimizer for Sigmoid Activation\relax }}{35}}
\newlabel{prf1_adam_dbn}{{4.25}{35}}
\@writefile{toc}{\contentsline {subsubsection}{Momentum Optimizer}{35}}
\@writefile{lot}{\contentsline {table}{\numberline {4.26}{\ignorespaces Precision, Recall, and F1 Score of DBN with Momentum Optimizer for Sigmoid Activation\relax }}{35}}
\newlabel{prf1_mom_dbn}{{4.26}{35}}
\@writefile{toc}{\contentsline {subsubsection}{RMSProp}{36}}
\@writefile{lot}{\contentsline {table}{\numberline {4.27}{\ignorespaces Precision, Recall, and F1 Score of DBN with RMSProp Optimizer for Sigmoid Activation\relax }}{36}}
\newlabel{prf1_rms_dbn}{{4.27}{36}}
\@writefile{toc}{\contentsline {subsubsection}{Stochastic Gradient Descent Optimizer}{36}}
\@writefile{lot}{\contentsline {table}{\numberline {4.28}{\ignorespaces Precision, Recall, and F1 Score of DBN with RMSProp Optimizer for Sigmoid Activation\relax }}{36}}
\newlabel{prf1_sgd_dbn}{{4.28}{36}}
\bibcite{Kaspersky}{1}
\bibcite{IDS}{2}
\bibcite{securityengineering}{3}
\bibcite{limitationOfIDS}{4}
\bibcite{ReLU}{5}
\bibcite{ELU}{6}
\bibcite{unsupervised}{7}
\bibcite{momentum}{8}
\bibcite{OptimizerGeneral}{9}
\bibcite{tensorflow_paper}{10}
\bibcite{googleSearch}{11}
\bibcite{challenge1}{12}
\bibcite{challenge2}{13}
\bibcite{autoencoder}{14}
\bibcite{autoencoder2}{15}
\bibcite{ksparseautoencoder}{16}
\bibcite{DBN}{17}
\bibcite{RBM}{18}
\bibcite{RBMuses}{19}
\bibcite{Greedy}{20}
\@writefile{toc}{\contentsline {chapter}{Appendix \numberline {A}Results of Supervised Training of Stacked Autoencoder}{39}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:super}{{A}{39}}
\@writefile{lot}{\contentsline {table}{\numberline {A.1}{\ignorespaces Settings used to evaluate stacked autoencoder in tflearn\relax }}{39}}
\newlabel{setting_tflearn_autoencoder}{{A.1}{39}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Adam Optimizer}{40}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces  Accuracy of Stacked Autoencoder with Adam optimizer for different activation \relax }}{40}}
\newlabel{fig:acc_adam}{{18}{40}}
\@writefile{lot}{\contentsline {table}{\numberline {A.2}{\ignorespaces Number of samples correctly identified for Adam Optimizer with different Activation functions\relax }}{40}}
\newlabel{confusion_adam_tflearn}{{A.2}{40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.1}Sigmoid Activation}{41}}
\@writefile{lot}{\contentsline {table}{\numberline {A.3}{\ignorespaces Precision Recall and F1-Score Values of Sigmoid Activation for RMSProp Optimizer\relax }}{41}}
\newlabel{classification sigmoid adam tflearn}{{A.3}{41}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.2}ReLu Activation}{41}}
\@writefile{lot}{\contentsline {table}{\numberline {A.4}{\ignorespaces Precision Recall and F1-Score Values of ReLU Activation for Adam Optimizer\relax }}{41}}
\newlabel{classification relu adam tflearn}{{A.4}{41}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.3}eLu Activation}{41}}
\@writefile{lot}{\contentsline {table}{\numberline {A.5}{\ignorespaces Precision Recall and F1-Score Values of elU Activation for Adam Optimizer\relax }}{41}}
\newlabel{classification elu adam tflearn}{{A.5}{41}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.4}Softplus Activation}{42}}
\@writefile{lot}{\contentsline {table}{\numberline {A.6}{\ignorespaces Precision Recall and F1-Score Values of Softplus Activation for Adam Optimizer\relax }}{42}}
\newlabel{classification softplus adam tflearn}{{A.6}{42}}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}RMSProp Optimizer}{42}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces  Accuracy of Stacked Autoencoder with RMSProp optimizer for different activation \relax }}{42}}
\newlabel{fig:acc_rms}{{19}{42}}
\@writefile{lot}{\contentsline {table}{\numberline {A.7}{\ignorespaces Number of samples correctly identified for RMSProp Optimizer with different Activation functions\relax }}{43}}
\newlabel{confusion_rms_tflearn}{{A.7}{43}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.1}Sigmoid Activation}{43}}
\@writefile{lot}{\contentsline {table}{\numberline {A.8}{\ignorespaces Precision Recall and F1-Score Values of Sigmoid Activation for RMSProp Optimizer\relax }}{43}}
\newlabel{classification sigmoid rms tflearn}{{A.8}{43}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.2}ReLu Activation}{43}}
\@writefile{lot}{\contentsline {table}{\numberline {A.9}{\ignorespaces Precision Recall and F1-Score Values of ReLU Activation for RMSProp Optimizer\relax }}{43}}
\newlabel{classification relu rms tflearn}{{A.9}{43}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.3}eLu Activation}{44}}
\@writefile{lot}{\contentsline {table}{\numberline {A.10}{\ignorespaces Precision Recall and F1-Score Values of eLU Activation for RMSProp Optimizer\relax }}{44}}
\newlabel{classification elu rms tflearn}{{A.10}{44}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.4}Softplus Activation}{44}}
\@writefile{lot}{\contentsline {table}{\numberline {A.11}{\ignorespaces Precision Recall and F1-Score Values of Softplus Activation for RMSProp Optimizer\relax }}{44}}
\newlabel{classification softplus rms tflearn}{{A.11}{44}}
\@writefile{toc}{\contentsline {section}{\numberline {A.3}Stochastic Gradient Descent Optimizer}{45}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces  Accuracy of Stacked Autoencoder with Stochastic Gradient Descent optimizer for different activation \relax }}{45}}
\newlabel{fig:acc_sgd}{{20}{45}}
\@writefile{lot}{\contentsline {table}{\numberline {A.12}{\ignorespaces Number of samples correctly identified for Stochastic Gradient Descent Optimizer with different Activation functions\relax }}{45}}
\newlabel{confusion_sgd}{{A.12}{45}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.1}Sigmoid Activation}{46}}
\@writefile{lot}{\contentsline {table}{\numberline {A.13}{\ignorespaces Precision Recall and F1-Score Values of Sigmoid Activation for Stochastic Gradient Descent Optimizer\relax }}{46}}
\newlabel{classification sigmoid sgd tflearn}{{A.13}{46}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.2}ReLU Activation}{46}}
\@writefile{lot}{\contentsline {table}{\numberline {A.14}{\ignorespaces Precision Recall and F1-Score Values of ReLU Activation for Stochastic Gradient Descent Optimizer\relax }}{46}}
\newlabel{classification relu sgd tflearn}{{A.14}{46}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.3}eLu Activation}{46}}
\@writefile{lot}{\contentsline {table}{\numberline {A.15}{\ignorespaces Precision Recall and F1-Score Values of eLU Activation for Stochastic Gradient Descent Optimizer\relax }}{46}}
\newlabel{classification elu sgd tflearn}{{A.15}{46}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.4}Softplus Activation}{47}}
\@writefile{lot}{\contentsline {table}{\numberline {A.16}{\ignorespaces Precision Recall and F1-Score Values of Softplus Activation for Stochastic Gradient Descent Optimizer\relax }}{47}}
\newlabel{classification softplus sgd tflearn}{{A.16}{47}}
\@writefile{toc}{\contentsline {section}{\numberline {A.4}Momentum Optimizer}{47}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces  Accuracy of Stacked Autoencoder with Momentum optimizer for different activation \relax }}{47}}
\newlabel{fig:acc_Momentum}{{21}{47}}
\@writefile{lot}{\contentsline {table}{\numberline {A.17}{\ignorespaces Number of samples correctly identified for Momentum Optimizer with different Activation functions\relax }}{48}}
\newlabel{confusion_Momentum}{{A.17}{48}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4.1}Sigmoid Activation}{48}}
\@writefile{lot}{\contentsline {table}{\numberline {A.18}{\ignorespaces Precision Recall and F1-Score Values of Sigmoid Activation for Momentum Optimizer\relax }}{48}}
\newlabel{classification sigmoid Momentum tflearn}{{A.18}{48}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4.2}ReLU Activation}{48}}
\@writefile{lot}{\contentsline {table}{\numberline {A.19}{\ignorespaces Precision Recall and F1-Score Values of ReLU Activation for Momentum Optimizer\relax }}{48}}
\newlabel{classification relu Momentum tflearn}{{A.19}{48}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4.3}eLu Activation}{49}}
\@writefile{lot}{\contentsline {table}{\numberline {A.20}{\ignorespaces Precision Recall and F1-Score Values of eLU Activation for Momentum Optimizer\relax }}{49}}
\newlabel{classification elu Momentum tflearn}{{A.20}{49}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4.4}Softplus Activation}{49}}
\@writefile{lot}{\contentsline {table}{\numberline {A.21}{\ignorespaces Precision Recall and F1-Score Values of Softplus Activation for Momentum Optimizer\relax }}{49}}
\newlabel{classification softplus Momentum tflearn}{{A.21}{49}}
\@writefile{toc}{\contentsline {chapter}{Appendix \numberline {B}Unsupervised Training Results of Stacked Autoencoder}{50}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:unsuper_tf}{{B}{50}}
\@writefile{toc}{\contentsline {section}{\numberline {B.1}Adam Optimizer}{50}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces  Accuracy of Stacked Autoencoder with Adam optimizer for different activation, Unsupervised Learning \relax }}{50}}
\newlabel{fig:acc_adam_tf}{{22}{50}}
\@writefile{lot}{\contentsline {table}{\numberline {B.1}{\ignorespaces Number of samples correctly identified for Adam Optimizer with different Activation functions, Unsupervised Learning\relax }}{51}}
\newlabel{confusion_adam_tf}{{B.1}{51}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1.1}Sigmoid Activation}{51}}
\@writefile{lot}{\contentsline {table}{\numberline {B.2}{\ignorespaces Precision Recall and F1-Score Values of Sigmoid Activation for Adam Optimizer, Unsupervised Learning\relax }}{51}}
\newlabel{classification sigmoid adam tf}{{B.2}{51}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1.2}ReLU Activation}{51}}
\@writefile{lot}{\contentsline {table}{\numberline {B.3}{\ignorespaces Precision Recall and F1-Score Values of ReLU Activation for Adam Optimizer, Unsupervised Learning\relax }}{51}}
\newlabel{classification ReLU adam tf}{{B.3}{51}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1.3}eLU Activation}{52}}
\@writefile{lot}{\contentsline {table}{\numberline {B.4}{\ignorespaces Precision Recall and F1-Score Values of eLU Activation for Adam Optimizer, Unsupervised Learning\relax }}{52}}
\newlabel{classification eLU adam tf}{{B.4}{52}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1.4}Softplus Activation}{52}}
\@writefile{lot}{\contentsline {table}{\numberline {B.5}{\ignorespaces Precision Recall and F1-Score Values of Softplus Activation for Adam Optimizer, Unsupervised Learning\relax }}{52}}
\newlabel{classification softplus adam tf}{{B.5}{52}}
\@writefile{toc}{\contentsline {section}{\numberline {B.2}RMSProp Optimizer}{53}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces  Accuracy of Stacked Autoencoder with RMSProp optimizer for different activation, Unsupervised Learning \relax }}{53}}
\newlabel{fig:acc_RMSProp_tf}{{23}{53}}
\@writefile{lot}{\contentsline {table}{\numberline {B.6}{\ignorespaces Number of samples correctly identified for RMSProp Optimizer with different Activation functions, Unsupervised Learning\relax }}{53}}
\newlabel{confusion_RMSProp_tf}{{B.6}{53}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2.1}Sigmoid Activation}{54}}
\@writefile{lot}{\contentsline {table}{\numberline {B.7}{\ignorespaces Precision Recall and F1-Score Values of Sigmoid Activation for RMSProp Optimizer, Unsupervised Learning\relax }}{54}}
\newlabel{classification sigmoid RMSProp tf}{{B.7}{54}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2.2}ReLU Activation}{54}}
\@writefile{lot}{\contentsline {table}{\numberline {B.8}{\ignorespaces Precision Recall and F1-Score Values of ReLU Activation for RMSProp Optimizer, Unsupervised Learning\relax }}{54}}
\newlabel{classification ReLU RMSProp tf}{{B.8}{54}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2.3}eLU Activation}{54}}
\@writefile{lot}{\contentsline {table}{\numberline {B.9}{\ignorespaces Precision Recall and F1-Score Values of eLU Activation for RMSProp Optimizer, Unsupervised Learning\relax }}{54}}
\newlabel{classification eLU RMSProp tf}{{B.9}{54}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2.4}Softplus Activation}{55}}
\@writefile{lot}{\contentsline {table}{\numberline {B.10}{\ignorespaces Precision Recall and F1-Score Values of Softplus Activation for RMSProp Optimizer, Unsupervised Learning\relax }}{55}}
\newlabel{classification softplus RMSProp tf}{{B.10}{55}}
\@writefile{toc}{\contentsline {section}{\numberline {B.3}Stochastic Gradient Descent Optimizer}{56}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces  Accuracy of Stacked Autoencoder with Stochastic Gradient Descent optimizer for different activation, Unsupervised Learning \relax }}{56}}
\newlabel{fig:acc_sgd_tf}{{24}{56}}
\@writefile{lot}{\contentsline {table}{\numberline {B.11}{\ignorespaces Number of samples correctly identified for Stochastic Gradient Descent Optimizer with different Activation functions, Unsupervised Learning\relax }}{56}}
\newlabel{confusion_sgd_tf}{{B.11}{56}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3.1}Sigmoid Activation}{57}}
\@writefile{lot}{\contentsline {table}{\numberline {B.12}{\ignorespaces Precision Recall and F1-Score Values of Sigmoid Activation for Stochastic Gradient Descent Optimizer, Unsupervised Learning\relax }}{57}}
\newlabel{classification sigmoid sgd tf}{{B.12}{57}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3.2}ReLU Activation}{57}}
\@writefile{lot}{\contentsline {table}{\numberline {B.13}{\ignorespaces Precision Recall and F1-Score Values of ReLU Activation for Stochastic Gradient Descent Optimizer, Unsupervised Learning\relax }}{57}}
\newlabel{classification ReLU sgd tf}{{B.13}{57}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3.3}eLU Activation}{57}}
\@writefile{lot}{\contentsline {table}{\numberline {B.14}{\ignorespaces Precision Recall and F1-Score Values of eLU Activation for Stochastic Gradient Descent Optimizer, Unsupervised Learning\relax }}{57}}
\newlabel{classification eLU sgd tf}{{B.14}{57}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3.4}Softplus Activation}{58}}
\@writefile{lot}{\contentsline {table}{\numberline {B.15}{\ignorespaces Precision Recall and F1-Score Values of Softplus Activation for Stochastic Gradient Descent Optimizer, Unsupervised Learning\relax }}{58}}
\newlabel{classification softplus sgd tf}{{B.15}{58}}
\@writefile{toc}{\contentsline {section}{\numberline {B.4}Momentum Optimizer}{58}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces  Accuracy of Stacked Autoencoder with Momentum optimizer for different activation, Unsupervised Learning \relax }}{58}}
\newlabel{fig:acc_sgd_tf}{{25}{58}}
\@writefile{lot}{\contentsline {table}{\numberline {B.16}{\ignorespaces Number of samples correctly identified for Momentum Optimizer with different Activation functions, Unsupervised Learning\relax }}{59}}
\newlabel{confusion_sgd_tf}{{B.16}{59}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.4.1}Sigmoid Activation}{59}}
\@writefile{lot}{\contentsline {table}{\numberline {B.17}{\ignorespaces Precision Recall and F1-Score Values of Sigmoid Activation for Momentum Optimizer, Unsupervised Learning\relax }}{59}}
\newlabel{classification sigmoid sgd tf}{{B.17}{59}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.4.2}ReLU Activation}{59}}
\@writefile{lot}{\contentsline {table}{\numberline {B.18}{\ignorespaces Precision Recall and F1-Score Values of ReLU Activation for Momentum Optimizer, Unsupervised Learning\relax }}{59}}
\newlabel{classification ReLU sgd tf}{{B.18}{59}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.4.3}eLU Activation}{60}}
\@writefile{lot}{\contentsline {table}{\numberline {B.19}{\ignorespaces Precision Recall and F1-Score Values of eLU Activation for Momentum Optimizer, Unsupervised Learning\relax }}{60}}
\newlabel{classification eLU sgd tf}{{B.19}{60}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.4.4}Softplus Activation}{60}}
\@writefile{lot}{\contentsline {table}{\numberline {B.20}{\ignorespaces Precision Recall and F1-Score Values of Softplus Activation for Momentum Optimizer, Unsupervised Learning\relax }}{60}}
\newlabel{classification softplus mom tf}{{B.20}{60}}
