\relax 
\citation{Kaspersky}
\citation{IDS}
\citation{IDS}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:intro}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Intrusion Detection System}{1}}
\newlabel{sec:introintrusion}{{1.1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Classification of Intrusion Detection System}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Network Intrusion Detection System}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Host based Intrusion Detection System}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Advantages of Network Based Intrusion Detection System}{2}}
\newlabel{sec:advantagesofNIDS}{{1.3}{2}}
\citation{securityengineering}
\citation{securityengineering}
\citation{limitationOfIDS}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Advantages of Host Based Intrusion Detection System}{3}}
\newlabel{sec:advantagesHostBasedIDS}{{1.4}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Limitations of Intrusion Detection Systems}{3}}
\newlabel{sec:limitsofIDS}{{1.5}{3}}
\citation{tensorflow_paper}
\citation{googleSearch}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Tensorflow}{4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:tensorflow}{{2}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction}{4}}
\newlabel{sec:tensor_intro}{{2.1}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Graph Construction and Basic Programming Concept}{5}}
\newlabel{sec:programmingtensorflow}{{2.2}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Operations, Kernels, Variables, and Sessions}{5}}
\newlabel{sec:constituentsoftensorflow}{{2.2.1}{5}}
\@writefile{toc}{\contentsline {subsubsection}{Operations and Kernels}{5}}
\newlabel{sec:ops_kernel}{{2.2.1}{5}}
\@writefile{toc}{\contentsline {subsubsection}{Variables}{5}}
\newlabel{variables}{{2.2.1}{5}}
\@writefile{toc}{\contentsline {subsubsection}{Session}{5}}
\newlabel{session}{{2.2.1}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Tensor}{5}}
\newlabel{tensor}{{2.2.2}{5}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Deep Neural Networks}{6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ref:DNN}{{3}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introduction}{6}}
\newlabel{sec:intro_dnn}{{3.1}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Artificial Neural Network}{6}}
\newlabel{ANN}{{3.2}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Structure of Artificial Neuron\relax }}{7}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:AN}{{1}{7}}
\newlabel{Artificial Neuron formula}{{1}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Structure of Artificial Neural Network\relax }}{8}}
\newlabel{fig:NN}{{2}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Artificial Neural Networks: Types}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Feed Forward and Recurrent Neural Network\relax }}{8}}
\newlabel{fig:FFRN}{{3}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Training a Deep Neural Network}{10}}
\newlabel{train}{{3.4}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Supervised Learning}{10}}
\newlabel{sec:supervisedLearning}{{3.4.1}{10}}
\citation{unsupervised}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Supervised Learning\relax }}{11}}
\newlabel{fig:supervised}{{4}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Unsupervised Learning}{11}}
\newlabel{sec:unsupervised}{{3.4.2}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Unsupervised Learning(K-Means)\relax }}{12}}
\newlabel{fig:cluster}{{5}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Reinforcement Learning}{12}}
\newlabel{sec:ReinforcementLearning}{{3.4.3}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Reinforcement Learning\relax }}{12}}
\newlabel{fig:reinforcement}{{6}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Activation Functions}{13}}
\newlabel{activationfunction}{{3.4.4}{13}}
\@writefile{toc}{\contentsline {subsubsection}{Sigmoid Activation Function}{13}}
\newlabel{sec:sigmoid}{{3.4.4}{13}}
\newlabel{eq:sig}{{2}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Sigmoid Activation Function\relax }}{13}}
\newlabel{fig:sigmoid}{{7}{13}}
\citation{ReLU}
\@writefile{toc}{\contentsline {subsubsection}{Step Function}{14}}
\newlabel{sec:step}{{3.4.4}{14}}
\newlabel{eq:step}{{3}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Step Activation Function\relax }}{14}}
\newlabel{fig:step}{{8}{14}}
\@writefile{toc}{\contentsline {subsubsection}{Rectified Linear Unit (ReLU)}{14}}
\newlabel{sec:ReLU}{{3.4.4}{14}}
\newlabel{eq:ReLU}{{4}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Rectified Linear Unit Activation Function\relax }}{14}}
\newlabel{fig:ReLU}{{9}{14}}
\citation{ELU}
\@writefile{toc}{\contentsline {subsubsection}{TanH Activation Function}{15}}
\newlabel{sec:tanh}{{3.4.4}{15}}
\newlabel{eq:tanh}{{5}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces TanH Activation Function\relax }}{15}}
\newlabel{fig:tanh}{{10}{15}}
\@writefile{toc}{\contentsline {subsubsection}{Exponential Linear Unit (eLU)}{15}}
\newlabel{sec:ELU}{{3.4.4}{15}}
\newlabel{eq:ELU}{{6}{15}}
\@writefile{toc}{\contentsline {subsubsection}{Softmax Activation Function}{15}}
\newlabel{sec:softmax}{{3.4.4}{15}}
\newlabel{eq:softmax}{{7}{15}}
\citation{OptimizerGeneral}
\citation{OptimizerGeneral}
\citation{momentum}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.5}Optimization Algorithm}{16}}
\newlabel{optimizer}{{3.4.5}{16}}
\@writefile{toc}{\contentsline {subsubsection}{Stochastic Gradient Descent Optimizer}{16}}
\newlabel{sgd}{{3.4.5}{16}}
\@writefile{toc}{\contentsline {subsubsection}{Adam Optimizer}{16}}
\newlabel{adam}{{3.4.5}{16}}
\@writefile{toc}{\contentsline {subsubsection}{Momentum Optimizer}{16}}
\newlabel{momentum}{{3.4.5}{16}}
\citation{OptimizerGeneral}
\citation{challenge1}
\citation{challenge2}
\citation{autoencoder}
\citation{autoencoder2}
\@writefile{toc}{\contentsline {subsubsection}{RMSProp Optimizer}{17}}
\newlabel{RMSProp}{{3.4.5}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Challenges in Training a Deep Neural Network}{17}}
\newlabel{challenges}{{3.5}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Stacked Autoencoder}{17}}
\newlabel{Autoencoder}{{3.6}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Structure}{18}}
\newlabel{structure}{{3.6.1}{18}}
\newlabel{eq:autoencoder_eq}{{8}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Autoencoder with single hidden layer\relax }}{18}}
\newlabel{fig:autoencoder}{{11}{18}}
\citation{ksparseautoencoder}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}Types of Autoencoders}{19}}
\newlabel{sec:types_autoencoder}{{3.6.2}{19}}
\@writefile{toc}{\contentsline {subsubsection}{Denoising Autoencoders}{19}}
\newlabel{sec:denoising_autoencoder}{{3.6.2}{19}}
\@writefile{toc}{\contentsline {subsubsection}{Sparse Autoencoder}{19}}
\newlabel{sec:sparse_autoencoder}{{3.6.2}{19}}
\citation{DBN}
\citation{RBM}
\citation{RBMuses}
\citation{Greedy}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Deep Belief Networks}{20}}
\newlabel{sec:deep_belief_network}{{3.7}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.1}Restricted Boltzmann Machine}{20}}
\newlabel{sec:RBM}{{3.7.1}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Deep Belief Network\relax }}{20}}
\newlabel{fig:RBM}{{12}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.2}Greedy Layer-Wise Training of Neural Networks}{20}}
\newlabel{greedy}{{3.7.2}{20}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Evaluation and Results}{21}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:EvaluationAndResults}{{4}{21}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}The Approach}{21}}
\newlabel{approach}{{4.1}{21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Parameters}{21}}
\@writefile{toc}{\contentsline {subsubsection}{Learning Rate}{21}}
\@writefile{toc}{\contentsline {subsubsection}{Epochs}{21}}
\@writefile{toc}{\contentsline {subsubsection}{Batch Size}{21}}
\@writefile{toc}{\contentsline {subsubsection}{Accuracy}{22}}
\@writefile{toc}{\contentsline {subsubsection}{Precision (P)}{22}}
\@writefile{toc}{\contentsline {subsubsection}{Recall (R)}{22}}
\@writefile{toc}{\contentsline {subsubsection}{F-Measure (F1-Score)}{22}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Data Set Evaluation}{23}}
\newlabel{sec:datasetEvaluation}{{4.2}{23}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Distribution of records in Test and Train Set\relax }}{23}}
\newlabel{table:test_train}{{4.1}{23}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Stacked Autoencoder}{23}}
\newlabel{sec:autoencoder}{{4.3}{23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Results}{23}}
\newlabel{results}{{4.3.1}{23}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Configuration of Autoencoder for Greedy Layer-Wise Pre-Training\relax }}{24}}
\newlabel{config_auto_greedy}{{4.2}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Adam Optimizer}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces  Accuracy of Adam Optimizer for different activation functions\relax }}{24}}
\newlabel{fig:accuracy_adam_greedy}{{13}{24}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Number of samples correctly identified for Adam Optimizer with different Activation functions\relax }}{25}}
\newlabel{confusion_adam}{{4.3}{25}}
\@writefile{toc}{\contentsline {subsubsection}{Sigmoid Activation}{25}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Adam Optimizer for Sigmoid Activation\relax }}{25}}
\newlabel{prf1_adam_sigmoid_auto}{{4.4}{25}}
\@writefile{toc}{\contentsline {subsubsection}{ReLU Activation}{25}}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Adam Optimizer for ReLU Activation\relax }}{25}}
\newlabel{prf1_adam_relu_auto}{{4.5}{25}}
\@writefile{toc}{\contentsline {subsubsection}{eLU Activation}{26}}
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Adam Optimizer for eLU Activation\relax }}{26}}
\newlabel{prf1_adam_elu_auto}{{4.6}{26}}
\@writefile{toc}{\contentsline {subsubsection}{Softplus Activation}{26}}
\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Adam Optimizer for Softplus Activation\relax }}{26}}
\newlabel{prf1_adam_softplus_auto}{{4.7}{26}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}RMSProp Optimizer}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces  Accuracy of RMSProp Optimizer for different activation functions\relax }}{27}}
\newlabel{fig:accuracy_rmsprop_greedy}{{14}{27}}
\@writefile{lot}{\contentsline {table}{\numberline {4.8}{\ignorespaces Number of samples correctly identified for RMSProp Optimizer with different Activation functions\relax }}{27}}
\newlabel{confusion_rmsprop}{{4.8}{27}}
\@writefile{toc}{\contentsline {subsubsection}{Sigmoid Activation}{28}}
\@writefile{lot}{\contentsline {table}{\numberline {4.9}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with RMSProp Optimizer for Sigmoid Activation\relax }}{28}}
\newlabel{prf1_rmsprop_sigmoid_auto}{{4.9}{28}}
\@writefile{toc}{\contentsline {subsubsection}{ReLU Activation}{28}}
\@writefile{lot}{\contentsline {table}{\numberline {4.10}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with RMSProp Optimizer for ReLU Activation\relax }}{28}}
\newlabel{prf1_rmsprop_relu_auto}{{4.10}{28}}
\@writefile{toc}{\contentsline {subsubsection}{eLU Activation}{28}}
\@writefile{lot}{\contentsline {table}{\numberline {4.11}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with RMSProp Optimizer for eLU Activation\relax }}{28}}
\newlabel{prf1_rmsprop_elu_auto}{{4.11}{28}}
\@writefile{toc}{\contentsline {subsubsection}{Softplus Activation}{29}}
\@writefile{lot}{\contentsline {table}{\numberline {4.12}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with RMSProp Optimizer for Softplus Activation\relax }}{29}}
\newlabel{prf1_rmsprop_elu_auto}{{4.12}{29}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Stochastic Gradient Descent Optimizer}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces  Accuracy of Stochastic Gradient Descent Optimizer for different activation functions\relax }}{29}}
\newlabel{fig:accuracy_sgd_greedy}{{15}{29}}
\@writefile{lot}{\contentsline {table}{\numberline {4.13}{\ignorespaces Number of samples correctly identified for Stochastic Gradient Descent Optimizer with different Activation functions\relax }}{30}}
\newlabel{confusion_sgd_greedy}{{4.13}{30}}
\@writefile{toc}{\contentsline {subsubsection}{Sigmoid Activation}{30}}
\@writefile{lot}{\contentsline {table}{\numberline {4.14}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Stochastic Gradient Descent Optimizer for Sigmoid Activation\relax }}{30}}
\newlabel{prf1_sgd_sigmoid_auto}{{4.14}{30}}
\@writefile{toc}{\contentsline {subsubsection}{ReLU Activation}{30}}
\@writefile{lot}{\contentsline {table}{\numberline {4.15}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Stochastic Gradient Descent Optimizer for ReLU Activation\relax }}{30}}
\newlabel{prf1_sgd_relu_auto}{{4.15}{30}}
\@writefile{toc}{\contentsline {subsubsection}{eLU Activation}{31}}
\@writefile{lot}{\contentsline {table}{\numberline {4.16}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Stochastic Gradient Descent Optimizer for eLU Activation\relax }}{31}}
\newlabel{prf1_sgd_elu_auto}{{4.16}{31}}
\@writefile{toc}{\contentsline {subsubsection}{Softplus Activation}{31}}
\@writefile{lot}{\contentsline {table}{\numberline {4.17}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Stochastic Gradient Descent Optimizer for Softplus Activation\relax }}{31}}
\newlabel{prf1_rmsprop_elu_auto}{{4.17}{31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.5}Momentum Optimizer}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces  Accuracy of Momentum Optimizer for different activation functions\relax }}{32}}
\newlabel{fig:accuracy_mom_greedy}{{16}{32}}
\@writefile{lot}{\contentsline {table}{\numberline {4.18}{\ignorespaces Number of samples correctly identified for Momentum Optimizer with different Activation functions\relax }}{32}}
\newlabel{confusion_mom}{{4.18}{32}}
\@writefile{toc}{\contentsline {subsubsection}{Sigmoid Activation}{33}}
\@writefile{lot}{\contentsline {table}{\numberline {4.19}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Momentum Optimizer for Sigmoid Activation\relax }}{33}}
\newlabel{prf1_mom_sigmoid_auto}{{4.19}{33}}
\@writefile{toc}{\contentsline {subsubsection}{ReLU Activation}{33}}
\@writefile{lot}{\contentsline {table}{\numberline {4.20}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Momentum Optimizer for ReLU Activation\relax }}{33}}
\newlabel{prf1_mom_relu_auto}{{4.20}{33}}
\@writefile{toc}{\contentsline {subsubsection}{eLU Activation}{33}}
\@writefile{lot}{\contentsline {table}{\numberline {4.21}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Momentum Optimizer for eLU Activation\relax }}{33}}
\newlabel{prf1_mom_elu_auto}{{4.21}{33}}
\@writefile{toc}{\contentsline {subsubsection}{Softplus Activation}{34}}
\@writefile{lot}{\contentsline {table}{\numberline {4.22}{\ignorespaces Precision, Recall, and F1 Score of Stacked Autoencoder with Momentum Optimizer for Softplus Activation\relax }}{34}}
\newlabel{prf1_mom_elu_auto}{{4.22}{34}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Deep Belief Network}{35}}
\newlabel{sec:dbn_eval}{{4.4}{35}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces  Accuracy of Deep Belief Network with different optimizers for Sigmoid activation \relax }}{35}}
\newlabel{fig:dbn_accu_sigmoid}{{17}{35}}
\@writefile{lot}{\contentsline {table}{\numberline {4.23}{\ignorespaces Parameters of DBN with Sigmoid Activation\relax }}{35}}
\newlabel{DBNSigmoidMomentum}{{4.23}{35}}
\@writefile{lot}{\contentsline {table}{\numberline {4.24}{\ignorespaces Number of samples correctly identified for DBN for different Optimizers with Sigmoid Activation functions\relax }}{36}}
\newlabel{DBN_predicted_attacks}{{4.24}{36}}
\@writefile{toc}{\contentsline {subsubsection}{Adam Optimizer}{36}}
\@writefile{lot}{\contentsline {table}{\numberline {4.25}{\ignorespaces Precision, Recall, and F1 Score of DBN with Adam Optimizer for Sigmoid Activation\relax }}{36}}
\newlabel{prf1_adam_dbn}{{4.25}{36}}
\@writefile{toc}{\contentsline {subsubsection}{Momentum Optimizer}{36}}
\@writefile{lot}{\contentsline {table}{\numberline {4.26}{\ignorespaces Precision, Recall, and F1 Score of DBN with Momentum Optimizer for Sigmoid Activation\relax }}{36}}
\newlabel{prf1_mom_dbn}{{4.26}{36}}
\@writefile{toc}{\contentsline {subsubsection}{RMSProp}{37}}
\@writefile{lot}{\contentsline {table}{\numberline {4.27}{\ignorespaces Precision, Recall, and F1 Score of DBN with RMSProp Optimizer for Sigmoid Activation\relax }}{37}}
\newlabel{prf1_rms_dbn}{{4.27}{37}}
\@writefile{toc}{\contentsline {subsubsection}{Stochastic Gradient Descent Optimizer}{37}}
\@writefile{lot}{\contentsline {table}{\numberline {4.28}{\ignorespaces Precision, Recall, and F1 Score of DBN with RMSProp Optimizer for Sigmoid Activation\relax }}{37}}
\newlabel{prf1_sgd_dbn}{{4.28}{37}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusion}{38}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{Kaspersky}{1}
\bibcite{IDS}{2}
\bibcite{securityengineering}{3}
\bibcite{limitationOfIDS}{4}
\bibcite{ReLU}{5}
\bibcite{ELU}{6}
\bibcite{unsupervised}{7}
\bibcite{momentum}{8}
\bibcite{OptimizerGeneral}{9}
\bibcite{tensorflow_paper}{10}
\bibcite{googleSearch}{11}
\bibcite{challenge1}{12}
\bibcite{challenge2}{13}
\bibcite{autoencoder}{14}
\bibcite{autoencoder2}{15}
\bibcite{ksparseautoencoder}{16}
\bibcite{DBN}{17}
\bibcite{RBM}{18}
\bibcite{RBMuses}{19}
\bibcite{Greedy}{20}
\@writefile{toc}{\contentsline {chapter}{Appendix \numberline {A}Results of Supervised Training of Stacked Autoencoder}{41}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:super}{{A}{41}}
\@writefile{lot}{\contentsline {table}{\numberline {A.1}{\ignorespaces Settings used to evaluate stacked autoencoder in tflearn\relax }}{41}}
\newlabel{setting_tflearn_autoencoder}{{A.1}{41}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Adam Optimizer}{42}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces  Accuracy of Stacked Autoencoder with Adam optimizer for different activation \relax }}{42}}
\newlabel{fig:acc_adam}{{18}{42}}
\@writefile{lot}{\contentsline {table}{\numberline {A.2}{\ignorespaces Number of samples correctly identified for Adam Optimizer with different Activation functions\relax }}{42}}
\newlabel{confusion_adam_tflearn}{{A.2}{42}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.1}Sigmoid Activation}{43}}
\@writefile{lot}{\contentsline {table}{\numberline {A.3}{\ignorespaces Precision Recall and F1-Score Values of Sigmoid Activation for RMSProp Optimizer\relax }}{43}}
\newlabel{classification sigmoid adam tflearn}{{A.3}{43}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.2}ReLu Activation}{43}}
\@writefile{lot}{\contentsline {table}{\numberline {A.4}{\ignorespaces Precision Recall and F1-Score Values of ReLU Activation for Adam Optimizer\relax }}{43}}
\newlabel{classification relu adam tflearn}{{A.4}{43}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.3}eLu Activation}{43}}
\@writefile{lot}{\contentsline {table}{\numberline {A.5}{\ignorespaces Precision Recall and F1-Score Values of elU Activation for Adam Optimizer\relax }}{43}}
\newlabel{classification elu adam tflearn}{{A.5}{43}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1.4}Softplus Activation}{44}}
\@writefile{lot}{\contentsline {table}{\numberline {A.6}{\ignorespaces Precision Recall and F1-Score Values of Softplus Activation for Adam Optimizer\relax }}{44}}
\newlabel{classification softplus adam tflearn}{{A.6}{44}}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}RMSProp Optimizer}{44}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces  Accuracy of Stacked Autoencoder with RMSProp optimizer for different activation \relax }}{44}}
\newlabel{fig:acc_rms}{{19}{44}}
\@writefile{lot}{\contentsline {table}{\numberline {A.7}{\ignorespaces Number of samples correctly identified for RMSProp Optimizer with different Activation functions\relax }}{45}}
\newlabel{confusion_rms_tflearn}{{A.7}{45}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.1}Sigmoid Activation}{45}}
\@writefile{lot}{\contentsline {table}{\numberline {A.8}{\ignorespaces Precision Recall and F1-Score Values of Sigmoid Activation for RMSProp Optimizer\relax }}{45}}
\newlabel{classification sigmoid rms tflearn}{{A.8}{45}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.2}ReLu Activation}{45}}
\@writefile{lot}{\contentsline {table}{\numberline {A.9}{\ignorespaces Precision Recall and F1-Score Values of ReLU Activation for RMSProp Optimizer\relax }}{45}}
\newlabel{classification relu rms tflearn}{{A.9}{45}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.3}eLu Activation}{46}}
\@writefile{lot}{\contentsline {table}{\numberline {A.10}{\ignorespaces Precision Recall and F1-Score Values of eLU Activation for RMSProp Optimizer\relax }}{46}}
\newlabel{classification elu rms tflearn}{{A.10}{46}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2.4}Softplus Activation}{46}}
\@writefile{lot}{\contentsline {table}{\numberline {A.11}{\ignorespaces Precision Recall and F1-Score Values of Softplus Activation for RMSProp Optimizer\relax }}{46}}
\newlabel{classification softplus rms tflearn}{{A.11}{46}}
\@writefile{toc}{\contentsline {section}{\numberline {A.3}Stochastic Gradient Descent Optimizer}{47}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces  Accuracy of Stacked Autoencoder with Stochastic Gradient Descent optimizer for different activation \relax }}{47}}
\newlabel{fig:acc_sgd}{{20}{47}}
\@writefile{lot}{\contentsline {table}{\numberline {A.12}{\ignorespaces Number of samples correctly identified for Stochastic Gradient Descent Optimizer with different Activation functions\relax }}{47}}
\newlabel{confusion_sgd}{{A.12}{47}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.1}Sigmoid Activation}{48}}
\@writefile{lot}{\contentsline {table}{\numberline {A.13}{\ignorespaces Precision Recall and F1-Score Values of Sigmoid Activation for Stochastic Gradient Descent Optimizer\relax }}{48}}
\newlabel{classification sigmoid sgd tflearn}{{A.13}{48}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.2}ReLU Activation}{48}}
\@writefile{lot}{\contentsline {table}{\numberline {A.14}{\ignorespaces Precision Recall and F1-Score Values of ReLU Activation for Stochastic Gradient Descent Optimizer\relax }}{48}}
\newlabel{classification relu sgd tflearn}{{A.14}{48}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.3}eLu Activation}{48}}
\@writefile{lot}{\contentsline {table}{\numberline {A.15}{\ignorespaces Precision Recall and F1-Score Values of eLU Activation for Stochastic Gradient Descent Optimizer\relax }}{48}}
\newlabel{classification elu sgd tflearn}{{A.15}{48}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3.4}Softplus Activation}{49}}
\@writefile{lot}{\contentsline {table}{\numberline {A.16}{\ignorespaces Precision Recall and F1-Score Values of Softplus Activation for Stochastic Gradient Descent Optimizer\relax }}{49}}
\newlabel{classification softplus sgd tflearn}{{A.16}{49}}
\@writefile{toc}{\contentsline {section}{\numberline {A.4}Momentum Optimizer}{49}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces  Accuracy of Stacked Autoencoder with Momentum optimizer for different activation \relax }}{49}}
\newlabel{fig:acc_Momentum}{{21}{49}}
\@writefile{lot}{\contentsline {table}{\numberline {A.17}{\ignorespaces Number of samples correctly identified for Momentum Optimizer with different Activation functions\relax }}{50}}
\newlabel{confusion_Momentum}{{A.17}{50}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4.1}Sigmoid Activation}{50}}
\@writefile{lot}{\contentsline {table}{\numberline {A.18}{\ignorespaces Precision Recall and F1-Score Values of Sigmoid Activation for Momentum Optimizer\relax }}{50}}
\newlabel{classification sigmoid Momentum tflearn}{{A.18}{50}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4.2}ReLU Activation}{50}}
\@writefile{lot}{\contentsline {table}{\numberline {A.19}{\ignorespaces Precision Recall and F1-Score Values of ReLU Activation for Momentum Optimizer\relax }}{50}}
\newlabel{classification relu Momentum tflearn}{{A.19}{50}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4.3}eLu Activation}{51}}
\@writefile{lot}{\contentsline {table}{\numberline {A.20}{\ignorespaces Precision Recall and F1-Score Values of eLU Activation for Momentum Optimizer\relax }}{51}}
\newlabel{classification elu Momentum tflearn}{{A.20}{51}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.4.4}Softplus Activation}{51}}
\@writefile{lot}{\contentsline {table}{\numberline {A.21}{\ignorespaces Precision Recall and F1-Score Values of Softplus Activation for Momentum Optimizer\relax }}{51}}
\newlabel{classification softplus Momentum tflearn}{{A.21}{51}}
\@writefile{toc}{\contentsline {chapter}{Appendix \numberline {B}Unsupervised Training Results of Stacked Autoencoder}{52}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{app:unsuper_tf}{{B}{52}}
\@writefile{toc}{\contentsline {section}{\numberline {B.1}Adam Optimizer}{52}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces  Accuracy of Stacked Autoencoder with Adam optimizer for different activation, Unsupervised Learning \relax }}{52}}
\newlabel{fig:acc_adam_tf}{{22}{52}}
\@writefile{lot}{\contentsline {table}{\numberline {B.1}{\ignorespaces Number of samples correctly identified for Adam Optimizer with different Activation functions, Unsupervised Learning\relax }}{53}}
\newlabel{confusion_adam_tf}{{B.1}{53}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1.1}Sigmoid Activation}{53}}
\@writefile{lot}{\contentsline {table}{\numberline {B.2}{\ignorespaces Precision Recall and F1-Score Values of Sigmoid Activation for Adam Optimizer, Unsupervised Learning\relax }}{53}}
\newlabel{classification sigmoid adam tf}{{B.2}{53}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1.2}ReLU Activation}{53}}
\@writefile{lot}{\contentsline {table}{\numberline {B.3}{\ignorespaces Precision Recall and F1-Score Values of ReLU Activation for Adam Optimizer, Unsupervised Learning\relax }}{53}}
\newlabel{classification ReLU adam tf}{{B.3}{53}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1.3}eLU Activation}{54}}
\@writefile{lot}{\contentsline {table}{\numberline {B.4}{\ignorespaces Precision Recall and F1-Score Values of eLU Activation for Adam Optimizer, Unsupervised Learning\relax }}{54}}
\newlabel{classification eLU adam tf}{{B.4}{54}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1.4}Softplus Activation}{54}}
\@writefile{lot}{\contentsline {table}{\numberline {B.5}{\ignorespaces Precision Recall and F1-Score Values of Softplus Activation for Adam Optimizer, Unsupervised Learning\relax }}{54}}
\newlabel{classification softplus adam tf}{{B.5}{54}}
\@writefile{toc}{\contentsline {section}{\numberline {B.2}RMSProp Optimizer}{55}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces  Accuracy of Stacked Autoencoder with RMSProp optimizer for different activation, Unsupervised Learning \relax }}{55}}
\newlabel{fig:acc_RMSProp_tf}{{23}{55}}
\@writefile{lot}{\contentsline {table}{\numberline {B.6}{\ignorespaces Number of samples correctly identified for RMSProp Optimizer with different Activation functions, Unsupervised Learning\relax }}{55}}
\newlabel{confusion_RMSProp_tf}{{B.6}{55}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2.1}Sigmoid Activation}{56}}
\@writefile{lot}{\contentsline {table}{\numberline {B.7}{\ignorespaces Precision Recall and F1-Score Values of Sigmoid Activation for RMSProp Optimizer, Unsupervised Learning\relax }}{56}}
\newlabel{classification sigmoid RMSProp tf}{{B.7}{56}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2.2}ReLU Activation}{56}}
\@writefile{lot}{\contentsline {table}{\numberline {B.8}{\ignorespaces Precision Recall and F1-Score Values of ReLU Activation for RMSProp Optimizer, Unsupervised Learning\relax }}{56}}
\newlabel{classification ReLU RMSProp tf}{{B.8}{56}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2.3}eLU Activation}{56}}
\@writefile{lot}{\contentsline {table}{\numberline {B.9}{\ignorespaces Precision Recall and F1-Score Values of eLU Activation for RMSProp Optimizer, Unsupervised Learning\relax }}{56}}
\newlabel{classification eLU RMSProp tf}{{B.9}{56}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.2.4}Softplus Activation}{57}}
\@writefile{lot}{\contentsline {table}{\numberline {B.10}{\ignorespaces Precision Recall and F1-Score Values of Softplus Activation for RMSProp Optimizer, Unsupervised Learning\relax }}{57}}
\newlabel{classification softplus RMSProp tf}{{B.10}{57}}
\@writefile{toc}{\contentsline {section}{\numberline {B.3}Stochastic Gradient Descent Optimizer}{58}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces  Accuracy of Stacked Autoencoder with Stochastic Gradient Descent optimizer for different activation, Unsupervised Learning \relax }}{58}}
\newlabel{fig:acc_sgd_tf}{{24}{58}}
\@writefile{lot}{\contentsline {table}{\numberline {B.11}{\ignorespaces Number of samples correctly identified for Stochastic Gradient Descent Optimizer with different Activation functions, Unsupervised Learning\relax }}{58}}
\newlabel{confusion_sgd_tf}{{B.11}{58}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3.1}Sigmoid Activation}{59}}
\@writefile{lot}{\contentsline {table}{\numberline {B.12}{\ignorespaces Precision Recall and F1-Score Values of Sigmoid Activation for Stochastic Gradient Descent Optimizer, Unsupervised Learning\relax }}{59}}
\newlabel{classification sigmoid sgd tf}{{B.12}{59}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3.2}ReLU Activation}{59}}
\@writefile{lot}{\contentsline {table}{\numberline {B.13}{\ignorespaces Precision Recall and F1-Score Values of ReLU Activation for Stochastic Gradient Descent Optimizer, Unsupervised Learning\relax }}{59}}
\newlabel{classification ReLU sgd tf}{{B.13}{59}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3.3}eLU Activation}{59}}
\@writefile{lot}{\contentsline {table}{\numberline {B.14}{\ignorespaces Precision Recall and F1-Score Values of eLU Activation for Stochastic Gradient Descent Optimizer, Unsupervised Learning\relax }}{59}}
\newlabel{classification eLU sgd tf}{{B.14}{59}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.3.4}Softplus Activation}{60}}
\@writefile{lot}{\contentsline {table}{\numberline {B.15}{\ignorespaces Precision Recall and F1-Score Values of Softplus Activation for Stochastic Gradient Descent Optimizer, Unsupervised Learning\relax }}{60}}
\newlabel{classification softplus sgd tf}{{B.15}{60}}
\@writefile{toc}{\contentsline {section}{\numberline {B.4}Momentum Optimizer}{60}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces  Accuracy of Stacked Autoencoder with Momentum optimizer for different activation, Unsupervised Learning \relax }}{60}}
\newlabel{fig:acc_sgd_tf}{{25}{60}}
\@writefile{lot}{\contentsline {table}{\numberline {B.16}{\ignorespaces Number of samples correctly identified for Momentum Optimizer with different Activation functions, Unsupervised Learning\relax }}{61}}
\newlabel{confusion_sgd_tf}{{B.16}{61}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.4.1}Sigmoid Activation}{61}}
\@writefile{lot}{\contentsline {table}{\numberline {B.17}{\ignorespaces Precision Recall and F1-Score Values of Sigmoid Activation for Momentum Optimizer, Unsupervised Learning\relax }}{61}}
\newlabel{classification sigmoid sgd tf}{{B.17}{61}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.4.2}ReLU Activation}{61}}
\@writefile{lot}{\contentsline {table}{\numberline {B.18}{\ignorespaces Precision Recall and F1-Score Values of ReLU Activation for Momentum Optimizer, Unsupervised Learning\relax }}{61}}
\newlabel{classification ReLU sgd tf}{{B.18}{61}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.4.3}eLU Activation}{62}}
\@writefile{lot}{\contentsline {table}{\numberline {B.19}{\ignorespaces Precision Recall and F1-Score Values of eLU Activation for Momentum Optimizer, Unsupervised Learning\relax }}{62}}
\newlabel{classification eLU sgd tf}{{B.19}{62}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.4.4}Softplus Activation}{62}}
\@writefile{lot}{\contentsline {table}{\numberline {B.20}{\ignorespaces Precision Recall and F1-Score Values of Softplus Activation for Momentum Optimizer, Unsupervised Learning\relax }}{62}}
\newlabel{classification softplus mom tf}{{B.20}{62}}
